# Human-comprehensible Fact-checking on Knowledge Graphs

# Résumé :

We propose a novel method for fact-checking on knowledge graphs. The
underlying idea is to employ automatic, sparse feature extractors
followed by a binary classifier that decides whether a fact is true or
false. In contrast to black-box methods, our method allows for
interactive reasoning on knowledge graphs where the users can take
common sense reasoning and external information into account. Such
interactive systems can increase the acceptance of various AI
applications based on knowledge graphs and can further lead to higher
efficiency, robustness, and fairness.

# Bio :

Marcel Hildebrandt started as PhD student under the supervision of
Volker Tresp at Siemens AG and the University of Munich (LMU)
in 2017. His research is focused on machine learning with
graph-structured data and industrial applications of AI. Prior to
joining Siemens, Marcel studied statistics at LSE in the UK and
mathematics at EPFL in Switzerland where he also worked in a lab for
computational biology.

# Lecture :

* [Nickel, M., Murphy, K., Tresp, V. and Gabrilovich, E., 2015. A review of relational machine learning for knowledge graphs. Proceedings of the IEEE, 104(1), pp.11-33.](https://arxiv.org/abs/1503.00759)
* [Das, R., Dhuliawala, S., Zaheer, M., Vilnis, L., Durugkar, I., Krishnamurthy, A., Smola, A. and McCallum, A., 2018. Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning. ICLR.](https://arxiv.org/pdf/1711.05851.pdf)
* [Irving, G., Christiano, P. and Amodei, D., 2018. AI safety via debate. arXiv preprint.](https://arxiv.org/abs/1805.00899)
* https://openai.com/blog/debate/
